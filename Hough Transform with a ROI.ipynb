{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the function to select region of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_region(image, vertices):\n",
    "    \"\"\"\n",
    "    Create the mask using the vertices and apply it to the input image\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(image)\n",
    "    if len(mask.shape)==2:\n",
    "        cv2.fillPoly(mask, vertices, 255)\n",
    "    else:\n",
    "        cv2.fillPoly(mask, vertices, (255,)*mask.shape[2]) # in case, the input image has a channel dimension        \n",
    "    return cv2.bitwise_and(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_region(image):\n",
    "    \"\"\"\n",
    "    It keeps the region surrounded by the `vertices` (i.e. polygon).  Other area is set to 0 (black).\n",
    "    \"\"\"\n",
    "    # first, define the polygon by vertices\n",
    "    rows, cols = image.shape[:2]\n",
    "    bottom_left  = [cols*0.05, rows*0.77]\n",
    "    top_left     = [cols*0.3, rows*0.55]\n",
    "    bottom_right = [cols*0.90, rows*0.77]\n",
    "    top_right    = [cols*0.6, rows*0.55] \n",
    "    # the vertices are an array of polygons (i.e array of arrays) and the data type must be integer\n",
    "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "    return filter_region(image, vertices)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture a Video \n",
    "apply the edge detection and apply the HoughTransform on the top of the image.\n",
    "call the ROI function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"High speed.mp4\")\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        video = cv2.VideoCapture(\"High speed.mp4\")\n",
    "        continue\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    #low_yellow = np.array([18,94,140])\n",
    "    #up_yellow = np.array([48,255,255])\n",
    "    #mask = cv2.inRange(hsv,low_yellow,up_yellow)\n",
    "    lower_white = np.array([0,0,0], dtype=np.uint8)\n",
    "    upper_white = np.array([0,0,255], dtype=np.uint8)\n",
    "   # mask = cv2.inRange(hsv,lower_white,upper_white)\n",
    "    \n",
    "   \n",
    "    edges = cv2.Canny(frame,75,150)\n",
    "    image = select_region(edges)\n",
    "    lines = cv2.HoughLinesP(image,1,np.pi/180,50,maxLineGap =50)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(frame,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "   \n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    \n",
    "    \n",
    "    key = cv2.waitKey(25)\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
